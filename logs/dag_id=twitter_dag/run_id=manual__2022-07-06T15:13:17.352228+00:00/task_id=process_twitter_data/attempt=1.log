[2022-07-06 12:13:24,624] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: twitter_dag.process_twitter_data manual__2022-07-06T15:13:17.352228+00:00 [queued]>
[2022-07-06 12:13:24,637] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: twitter_dag.process_twitter_data manual__2022-07-06T15:13:17.352228+00:00 [queued]>
[2022-07-06 12:13:24,637] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-07-06 12:13:24,637] {taskinstance.py:1357} INFO - Starting attempt 1 of 4
[2022-07-06 12:13:24,637] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-07-06 12:13:24,661] {taskinstance.py:1377} INFO - Executing <Task(DatabricksRunNowOperator): process_twitter_data> on 2022-07-06 15:13:17.352228+00:00
[2022-07-06 12:13:24,663] {standard_task_runner.py:52} INFO - Started process 13811 to run task
[2022-07-06 12:13:24,666] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'twitter_dag', 'process_twitter_data', 'manual__2022-07-06T15:13:17.352228+00:00', '--job-id', '51', '--raw', '--subdir', 'DAGS_FOLDER/twitter_dag.py', '--cfg-path', '/tmp/tmpkm9x1jpm', '--error-file', '/tmp/tmposzwjm8c']
[2022-07-06 12:13:24,667] {standard_task_runner.py:80} INFO - Job 51: Subtask process_twitter_data
[2022-07-06 12:13:24,732] {task_command.py:370} INFO - Running <TaskInstance: twitter_dag.process_twitter_data manual__2022-07-06T15:13:17.352228+00:00 [running]> on host nicholas-VirtualBox
[2022-07-06 12:13:24,815] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=nicholas.comuni@outlook.com
AIRFLOW_CTX_DAG_OWNER=Nicholas
AIRFLOW_CTX_DAG_ID=twitter_dag
AIRFLOW_CTX_TASK_ID=process_twitter_data
AIRFLOW_CTX_EXECUTION_DATE=2022-07-06T15:13:17.352228+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-06T15:13:17.352228+00:00
[2022-07-06 12:13:24,826] {base.py:68} INFO - Using connection ID 'databricks_conn' for task execution.
[2022-07-06 12:13:24,832] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:13:25,591] {databricks.py:49} INFO - Run submitted with run_id: 5242
[2022-07-06 12:13:25,592] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:13:26,149] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:13:26,706] {databricks.py:71} INFO - process_twitter_data in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2022-07-06 12:13:26,706] {databricks.py:72} INFO - View run status, Spark UI, and logs at https://adb-770153189229877.17.azuredatabricks.net/?o=770153189229877#job/711735064242409/run/5242
[2022-07-06 12:13:26,706] {databricks.py:73} INFO - Sleeping for 30 seconds.
[2022-07-06 12:13:56,736] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:13:57,307] {databricks.py:71} INFO - process_twitter_data in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2022-07-06 12:13:57,307] {databricks.py:72} INFO - View run status, Spark UI, and logs at https://adb-770153189229877.17.azuredatabricks.net/?o=770153189229877#job/711735064242409/run/5242
[2022-07-06 12:13:57,307] {databricks.py:73} INFO - Sleeping for 30 seconds.
[2022-07-06 12:14:27,328] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:14:27,878] {databricks.py:71} INFO - process_twitter_data in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2022-07-06 12:14:27,878] {databricks.py:72} INFO - View run status, Spark UI, and logs at https://adb-770153189229877.17.azuredatabricks.net/?o=770153189229877#job/711735064242409/run/5242
[2022-07-06 12:14:27,878] {databricks.py:73} INFO - Sleeping for 30 seconds.
[2022-07-06 12:14:57,908] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:14:58,505] {databricks.py:71} INFO - process_twitter_data in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2022-07-06 12:14:58,505] {databricks.py:72} INFO - View run status, Spark UI, and logs at https://adb-770153189229877.17.azuredatabricks.net/?o=770153189229877#job/711735064242409/run/5242
[2022-07-06 12:14:58,505] {databricks.py:73} INFO - Sleeping for 30 seconds.
[2022-07-06 12:15:05,420] {local_task_job.py:220} WARNING - State of this instance has been externally set to None. Terminating instance.
[2022-07-06 12:15:05,428] {process_utils.py:125} INFO - Sending Signals.SIGTERM to group 13811. PIDs of all processes in the group: [13811]
[2022-07-06 12:15:05,428] {process_utils.py:80} INFO - Sending the signal Signals.SIGTERM to group 13811
[2022-07-06 12:15:05,428] {taskinstance.py:1541} ERROR - Received SIGTERM. Terminating subprocesses.
[2022-07-06 12:15:05,431] {base.py:68} INFO - Using connection ID 'databricks_conn' for task execution.
[2022-07-06 12:15:05,433] {databricks_base.py:406} INFO - Using token auth. For security reasons, please set token in Password field instead of extra
[2022-07-06 12:15:06,173] {databricks.py:661} INFO - Task: process_twitter_data with run_id: 5242 was requested to be cancelled.
[2022-07-06 12:15:06,184] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/nicholas/.local/lib/python3.10/site-packages/airflow/providers/databricks/operators/databricks.py", line 655, in execute
    _handle_databricks_operator_execution(self, hook, self.log, context)
  File "/home/nicholas/.local/lib/python3.10/site-packages/airflow/providers/databricks/operators/databricks.py", line 74, in _handle_databricks_operator_execution
    time.sleep(operator.polling_period_seconds)
  File "/home/nicholas/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1543, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2022-07-06 12:15:06,189] {taskinstance.py:1395} INFO - Marking task as UP_FOR_RETRY. dag_id=twitter_dag, task_id=process_twitter_data, execution_date=20220706T151317, start_date=20220706T151324, end_date=20220706T151506
[2022-07-06 12:15:06,199] {standard_task_runner.py:92} ERROR - Failed to execute job 51 for task process_twitter_data ((sqlite3.IntegrityError) FOREIGN KEY constraint failed
[SQL: INSERT INTO task_fail (task_id, dag_id, run_id, map_index, start_date, end_date, duration) VALUES (?, ?, ?, ?, ?, ?, ?)]
[parameters: ('process_twitter_data', 'twitter_dag', 'manual__2022-07-06T15:13:17.352228+00:00', -1, '2022-07-06 15:13:24.625389', '2022-07-06 15:15:06.188771', 101)]
(Background on this error at: http://sqlalche.me/e/14/gkpj); 13811)
[2022-07-06 12:15:06,224] {process_utils.py:75} INFO - Process psutil.Process(pid=13811, status='terminated', exitcode=1, started='12:13:23') (13811) terminated with exit code 1
